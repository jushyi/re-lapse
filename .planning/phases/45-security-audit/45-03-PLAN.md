---
phase: 45-security-audit
plan: 03
type: execute
---

<objective>
Harden Cloud Functions input validation and abuse prevention — cap @mention extraction, validate trigger input fields, and fix non-atomic deletion operations.

Purpose: Prevent abuse vectors where unlimited @mentions trigger unbounded Firestore queries (DoS), unvalidated trigger inputs cause unexpected behavior, and multi-step deletions leave orphaned data on partial failure.
Output: Updated functions/index.js with mention limits, input validation, and transactional deletions.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/phase-prompt.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/45-security-audit/45-CONTEXT.md
@.planning/phases/45-security-audit/45-01-PLAN.md
@.planning/phases/45-security-audit/45-02-PLAN.md
@functions/index.js

**Critical findings from security audit:**

1. HIGH: sendCommentNotification (line ~1639) extracts @mentions with `/@(\w+)/g` — no limit on matches. A comment with 100+ @mentions triggers 100+ Firestore user lookups and notification sends. DoS vector.
2. HIGH: sendTaggedPhotoNotification (line ~1275-1276) processes taggedUserIds array without validating array length, element types, or deduplication.
3. HIGH: processScheduledPhotoDeletions (line ~2309-2383) performs multi-step deletion (albums → comments → likes → storage → photo doc) without transactions. Partial failure leaves orphaned data.
4. MEDIUM: sendReactionNotification (line ~1022-1041) processes reaction data without validating emoji format or count types.
5. MEDIUM: sendCommentNotification (line ~1555-1558) truncates text without checking UTF-8 boundaries (could split multi-byte emoji).
   </context>

<tasks>

<task type="auto">
  <name>Task 1: Cap @mentions and validate Firestore trigger inputs</name>
  <files>functions/index.js</files>
  <action>
**@mention limit in sendCommentNotification:**

1. After the regex extraction of mentions (`const mentions = (comment.text || '').match(/@(\w+)/g) || []`), add a cap:

```javascript
const MAX_MENTIONS_PER_COMMENT = 10;
const mentions = (comment.text || '').match(/@(\w+)/g) || [];
const cappedMentions = mentions.slice(0, MAX_MENTIONS_PER_COMMENT);
```

Use `cappedMentions` instead of `mentions` for the rest of the function. Log a warning if mentions were capped: `logger.warn('sendCommentNotification: Mentions capped', { total: mentions.length, capped: MAX_MENTIONS_PER_COMMENT })`.

2. Add the `MAX_MENTIONS_PER_COMMENT` constant near the top of the file alongside other constants (REACTION_DEBOUNCE_MS, TAG_DEBOUNCE_MS).

**Tagged photo notification validation:**

3. In sendTaggedPhotoNotification, after extracting `taggedUserIds` from the document, add validation:

```javascript
// Validate taggedUserIds
if (!Array.isArray(after.taggedUserIds)) {
  logger.warn('sendTaggedPhotoNotification: taggedUserIds is not an array', { photoId });
  return null;
}

// Cap tagged users to prevent abuse
const MAX_TAGS_PER_PHOTO = 20;
const taggedUserIds = after.taggedUserIds.slice(0, MAX_TAGS_PER_PHOTO);

// Deduplicate
const uniqueTaggedIds = [...new Set(taggedUserIds)];

// Filter out self-tags
const validTaggedIds = uniqueTaggedIds.filter(
  id => typeof id === 'string' && id.length > 0 && id !== photoOwnerId
);
```

Use `validTaggedIds` for the rest of the function. Add `MAX_TAGS_PER_PHOTO` constant near the top.

**Reaction notification validation:**

4. In sendReactionNotification, add type validation when processing reaction changes:

```javascript
// Validate reaction count is a number
if (typeof after.reactionCount !== 'number' || typeof (before.reactionCount || 0) !== 'number') {
  logger.warn('sendReactionNotification: Invalid reaction count type', { photoId });
  return null;
}
```

**Comment text truncation fix:**

5. In sendCommentNotification where comment text is truncated for the notification body, replace simple substring with a UTF-8 safe truncation. Instead of `comment.text.substring(0, 50)`, use:

```javascript
const MAX_NOTIFICATION_TEXT = 50;
const truncatedText = [...(comment.text || '')].slice(0, MAX_NOTIFICATION_TEXT).join('');
const displayText =
  truncatedText.length < (comment.text || '').length ? truncatedText + '...' : truncatedText;
```

This uses spread to split by Unicode code points rather than UTF-16 code units, preventing mid-emoji splits.

**What to avoid:** Do NOT change the debounce logic (pendingReactions, pendingTags) — while in-memory storage isn't ideal, migrating to Firestore-based debounce is a larger change that risks breaking existing notification batching. The current approach handles cold starts gracefully (worst case: one notification isn't batched).
</action>
<verify>Search for `MAX_MENTIONS_PER_COMMENT` and `MAX_TAGS_PER_PHOTO` constants. Verify mentions are sliced before processing. Verify taggedUserIds validated as array, deduplicated, self-tags filtered. Verify reaction count type check exists. Verify text truncation uses spread operator for UTF-8 safety.</verify>
<done>@mentions capped at 10 per comment, tagged users capped at 20 with deduplication and type validation, reaction count type-checked, comment text truncation is UTF-8 safe.</done>
</task>

<task type="auto">
  <name>Task 2: Fix non-atomic deletion operations</name>
  <files>functions/index.js</files>
  <action>
**Fix processScheduledPhotoDeletions:**

The current implementation deletes albums → comments → likes → storage → photo doc in separate steps without atomicity. If any step fails, earlier deletes can't be rolled back.

1. **Group Firestore operations into a single batch**: Collect all Firestore delete/update operations and commit them as one batch at the end. This makes Firestore changes atomic:

```javascript
const batch = db.batch();

// Album updates — add to batch instead of committing immediately
for (const albumDoc of albumsSnapshot.docs) {
  const updatedPhotoIds = albumDoc.data().photoIds.filter(id => id !== photoId);
  const updates = { photoIds: updatedPhotoIds };
  if (albumDoc.data().coverPhotoId === photoId) {
    updates.coverPhotoId = updatedPhotoIds[0] || null;
  }
  batch.update(albumDoc.ref, updates);
}

// Comment likes — add deletes to batch
for (const commentDoc of commentsSnapshot.docs) {
  const likesSnapshot = await commentDoc.ref.collection('likes').get();
  likesSnapshot.docs.forEach(likeDoc => batch.delete(likeDoc.ref));
  batch.delete(commentDoc.ref);
}

// Photo document delete — add to batch
batch.delete(photoDoc.ref);

// Commit all Firestore changes atomically
await batch.commit();
```

2. **Move Storage deletion AFTER Firestore batch succeeds**: If Firestore batch fails, no data is deleted. If Storage deletion fails after Firestore succeeds, log the orphaned file for later cleanup but don't fail the operation:

```javascript
// Storage cleanup (best-effort after Firestore success)
try {
  const bucket = admin.storage().bucket();
  // ... delete storage files ...
} catch (storageError) {
  logger.error('processScheduledPhotoDeletions: Storage cleanup failed - orphaned file', {
    photoId,
    userId,
    error: storageError.message,
  });
  // Continue — Firestore data already cleaned up
}
```

3. **Handle Firestore 500-write batch limit**: If a photo has many comments with many likes, the batch could exceed 500 writes. Add a check: if total operations exceed 400 (leaving buffer), split into multiple sequential batches. For each batch, group related operations together (all likes for one comment in same batch).

**Fix deleteUserAccount batch operations:**

4. Apply the same batching pattern to the deleteUserAccount function. Currently it uses separate batches for photos, friendships, notifications, etc. Combine related operations where possible, but keep them in logical groups (photos batch, friendships batch, etc.) since a single user could have more than 500 related documents.

5. Ensure Storage deletions happen AFTER their corresponding Firestore batch succeeds, not interleaved.

**What to avoid:** Do NOT use Firestore transactions (runTransaction) for deletions — transactions are limited to 500 writes and require all reads before writes, which doesn't work well for cascading deletes. Batched writes are the correct pattern here. Do NOT try to make Storage + Firestore atomic — they're different systems. Accept Storage cleanup as best-effort after Firestore success.
</action>
<verify>Read the updated deletion functions. Verify: Firestore operations are batched together, Storage deletion happens after Firestore batch commits, batch size is checked against 500 limit, error handling logs orphaned files on Storage failure.</verify>
<done>Photo and account deletion operations use atomic Firestore batches, Storage cleanup is best-effort after Firestore success, batch size limits are respected, orphaned files are logged for later cleanup.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] MAX_MENTIONS_PER_COMMENT constant exists and is used
- [ ] MAX_TAGS_PER_PHOTO constant exists and is used
- [ ] @mentions sliced before Firestore lookups
- [ ] taggedUserIds validated, deduplicated, self-tags filtered
- [ ] Reaction count type-checked before comparison
- [ ] Comment text truncation is UTF-8 safe
- [ ] processScheduledPhotoDeletions uses atomic Firestore batch
- [ ] Storage deletion happens after Firestore batch success
- [ ] deleteUserAccount batches are logically grouped
- [ ] Batch size checked against 500 limit
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No syntax errors in functions/index.js
- @mention abuse vector closed with reasonable cap
- Tagged photo notifications validated and capped
- Deletion operations are atomic at Firestore level
- Partial failures don't leave orphaned Firestore data
  </success_criteria>

<output>
After completion, create `.planning/phases/45-security-audit/45-03-SUMMARY.md`
</output>
